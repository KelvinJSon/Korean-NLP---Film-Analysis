{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Importing various packages\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import re \n",
    "import urllib.request\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import seaborn as sns \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "print(\"Import Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Getting the Korean film reviews\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")\n",
    "train = pd.read_table('ratings_train.txt') #splitting vetween training and test datasets\n",
    "test = pd.read_table('ratings_test.txt')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Dropping numerical ID column as it is not helpful\n",
    "train = train.drop(['id'],axis=1) \n",
    "test = test.drop(['id'],axis=1)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Checking the training data for any null values and locating them\n",
    "print(train.isnull().values.any())\n",
    "train.loc[train.document.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Dropping null reviews in training\n",
    "train = train.dropna()\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Creating another column where punctuations are removed for the review\n",
    "train['word_n_2']=train['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\" \")\n",
    "test['document']=test['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\" \")\n",
    "test['document'].replace('', np.nan, inplace=True)\n",
    "test = test.dropna()\n",
    "train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Tokenization and Removing Stopwords\n",
    "import os\n",
    "'JAVA_HOME' in os.environ\n",
    "from tqdm import tqdm\n",
    "os.environ['JAVA_HOME'] = r'C:\\Program Files\\Java\\jdk-17.0.1'\n",
    "okt = Okt()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "X_train = []\n",
    "X_test = []\n",
    "for sentence in tqdm(train['document']):\n",
    "    tokenized_sentence = okt.morphs(sentence, stem=True) # Train set tokenization\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # train set stopwords\n",
    "    X_train.append(stopwords_removed_sentence)\n",
    "for sentence in tqdm(test['document']):\n",
    "    tokenized_sentence = okt.morphs(sentence, stem=True) # Test set tokenization\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # test set stowords\n",
    "    X_test.append(stopwords_removed_sentence)\n",
    "print('Max Length for Reviews :',max(len(review) for review in X_train))\n",
    "print('Average Length of Reviews :',sum(map(len, X_train))/len(X_train))\n",
    "plt.hist([len(review) for review in X_train], bins=50)\n",
    "plt.xlabel('Length of Review Samples')\n",
    "plt.ylabel('Number of Review samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Limiting tokens to words that have only shown up more than 4h times \n",
    "max_features = 9308 # Number of words that have popped up more than 4 times in the training set\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Padding and cutting reviews when they are > 50 words\n",
    "drop_train = [index for index, sentence in enumerate(X_test) if len(sentence) <1]\n",
    "X_test = np.delete(X_test, drop_train, axis=0)\n",
    "max_len = 50\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "y_train = np.array(train['label'])\n",
    "y_test = np.array(test['label'])\n",
    "y_test = np.delete(y_test, drop_train, axis=0)\n",
    "embed_size = 128\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_size))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences = True)))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 3\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the best model used for our data\n",
    "from tensorflow.keras.models import load_model\n",
    "loaded_model = load_model('best_model.h5')\n",
    "print(\"\\n Test Accuracy: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating model performance\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,classification_report\n",
    "import scikitplot as skplt\n",
    "\n",
    "# Making predictions using 0.5 as the cutooff\n",
    "predictions = loaded_model.predict(X_test)\n",
    "predictions = (predictions >= 0.5)\n",
    "from scikitplot.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(y_test,predictions)\n",
    "acc_score = accuracy_score(y_test,predictions)\n",
    "pre_score = precision_score(y_test,predictions)\n",
    "rec_score = recall_score(y_test,predictions)\n",
    "print('Accuracy_score: ',acc_score)\n",
    "print('Precision_score: ',pre_score)\n",
    "print('Recall_score: ',rec_score)\n",
    "print(\"-\"*50)\n",
    "cr = classification_report(y_test,predictions)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting ROC curve\n",
    "predictions_probability = loaded_model.predict(X_test)\n",
    "fpr,tpr,thresholds = roc_curve(y_test,predictions_probability[:,0])\n",
    "plt.plot(fpr,tpr)\n",
    "plt.plot([0,1])\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
